[propagation]

# Possible methods for transferring files to and from the machine.
#
# If neither SCP nor GUC is configured, propagation will fail.
# If you want that, better to disable propagation in the Nimbus service
# configuration than to let it fail here later on by not finding scp or guc.
#
# Both can be configured, it is the central service that ultimately picks the
# mechanism used for a particular deployment.
#
# Can be absolute path. If not, PATH is used for resolution.

scp: /usr/bin/scp
#guc: /opt/globus/bin/globus-url-copy
cp: /bin/cp


# If using scp, if user is not specified in URL (e.g., scp://lily@host/path),
# then this configuration will allow you to make a default other than the
# account that the workspace-control program runs in.  If a default is
# necessary and this is not configured, then the scp invocation does not
# specify a user, making it default to the account that workspace-control
# is running under.
#scp_user: bob


# Set this to 'true' to enable http based propagation.  The service node
# has a configuration for the allowed hostnames that may be pulled from.
http: false

# Set this to 'true' to enable https based propagation.  The service node
# has a configuration for the allowed hostnames that may be pulled from.
# This allows you to authenticate with the server with an x509 credential.
https: false

# Set this to 'true' to allow cross server redirects from https.
# You might want this to be false if you have a very strict whitelist and 
# do not trust your https servers to not redirect to a server that isn't on
# the whitelist
https-cross-server-redirect: true

# Hadoop Distributed File System (hdfs)
# Make this point to the hadoop executable of your install.  Environment
# variables of the form $var and ${var} will be expanded if possible.
#
# Advanced feature, uncomment to enable.
#
# When enabled, the user must use hdfs:// URLs in the propagation request
# which will currently bypass the notion of external/internal namespaces
# for files that Nimbus 2.5 introduces.

#hdfs: /usr/bin/hadoop

# Set to 'true' to enable LANTorrent
lantorrent: false

lantorrentport: 2893
# if lantorrentip is not specified then it will be assumed that the
# request program is being run from ssh and the contact information will
# come from the SSH_CLIENT env
#lantorrentip: x.x.x.x
ssh: /usr/bin/ssh
lantorrentexe: /opt/nimbus/bin/ltclient.sh
